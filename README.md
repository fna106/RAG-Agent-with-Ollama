# RAG-Agent-with-Ollama
A Retrieval-Augmented Generation (RAG) agent built with Ollama to answers questions grounded in local documents, with transparent retrieval and citations.

For this project, Llama 3.1 (with 8B parameter) model was selected because it can run well on any local machine with 16 GB of RAM
The size of the model is only 4.7 GB and doesn't require a large stroage space.


[01/27/2026]:
RAG_final.ipynb and RAG_roar_collab_test.ipynb were created to show and test the implementation of RAG on ROAR Collab or on a local machince.
